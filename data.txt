То, что мы получили, специалисты называют Малое Репрезентативное Представление (МРП), “малое” - потому, что у нас всего 2 вещественных числа отражают вектор из 784 вещественных чисел, а “репрезентативное” - оно потому, что отражает внутри сети внешний мир, то есть зная лишь эти два значения, мы можем оценить что в данный момент “видит” сеть, какую цифру и даже примерную форму её начертания. Можно сказать, что Малое Репрезентативное Представление (МРП) это некая модель мира, только сети пришлось сделать очень простую модель, малую, всего два числа, хотя внешний мир более сложен и представляет собой наборы из 784 вещественных чисел.
Давайте взглянем подробнее, что из себя представляет эта Малое Репрезентативное Представление (МРП), мы видим несколько областей которые будут соответствовать определённым классам и соседние точки будут соответствовать очень близким по начертанию цифрам. Получается МРП может помочь существенно упростить процесс обучению распознавания. Мы можем взять обученный декодер, отбросив энкодер, добавить небольшой персептрон и достаточно быстро новую сеть научить распознавать рукописные цифры (это называется transfer learning, или перенос обучения), то есть сначала наша сеть, или её первая конфигурация обучалась только на изображениях без связи их с фактическим числом, такое вот самообучение (без учителя) для получения МРП, а затем следующая конфигурация используя полученное МРП, обучается на сопоставлении изображения и метки цифры, обучение с учителем, и делает это значительно быстрее, чем сеть которая будет обучаться сразу на сопоставлении.
По сути здесь класс цифры определяется некоторыми диапазонами активности двух нейронов. Эти диапазоны или области как мы видим на диаграмме, можно назвать некими эмбеддингами, представительствами классов внутри сети, которые сформировались в процессе самообучения.
Далее мы поговорит о том, что из себя представляет Малое Репрезентативное Представление (МРП) в биологических сетях, в мозге, как в нём представлены эти эмбеддинги, но для начала выделим некоторые качества этих сущностей для искусственных нейронных сетей. Во-первых, в МРП задействован слой целиком, все нейроны слоя имеют значение. Представим что мы убрали из сети один из двух нейронов, детектировать точно что “видит” сеть по одному нейрону будет проблематично, не всегда можно ответить даже на вопрос, а видит ли сейчас сеть, например, цифру “5”. Да, существует прунинг, но он возможен только при избыточном количестве нейронов, когда можно убрать нейроны без последствий для МРП. Во-вторых, чем больше нейронов в слое задействованном в МРП тем сложнее выделить фичи, так как каждый нейрон создает свое измерение в пространстве представительств классов, 2 нейрона - 2 измерения, 10 нейронов - 10 измерений… и все 10 будут взаимозависимы. В третьих, очевидная для искусственных сетей вещь, все нейроны слоя или даже всей сети, при каждом такте обучения вовлечены в него, каждый нейрон получит свою корректировку весов.

